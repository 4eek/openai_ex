# OpenaiEx Usage Notebook

```elixir
my_app_root = Path.join(__DIR__, "..")

Mix.install(
  [
    {:openai_ex, path: my_app_root}
  ],
  lockfile: Path.join(my_app_root, "mix.lock")
)
```

## Usage

This library is a thin wrapper around the OpenAI API client. It mirrors the API structure of the existing official clients in Python and JS.

Instead of repeating the documentation from that API, I have provided links to the actual API reference.

<!-- livebook:{"break_markdown":true} -->

### [Authentication](https://platform.openai.com/docs/api-reference/authentication)

Following API best practices, the tokens are stored in environment variables.

Default organization.

```elixir
# You can use LB_OPENAI_API_KEY in Livebook
apikey = System.fetch_env!("OPENAI_API_KEY")
openai = OpenaiEx.new(apikey)
```

Specified organization (uncomment to run)

```elixir
# organization = System.fetch_env!("OPENAI_ORGANIZATION")
# openai = OpenAIEx.new(apikey, organization)
```

### [Model](https://platform.openai.com/docs/api-reference/models)

```elixir
alias OpenaiEx.Model
```

To [list](https://platform.openai.com/docs/api-reference/models/list) all models

```elixir
openai |> Model.list()
```

To [retrieve](https://platform.openai.com/docs/api-reference/models/retrieve) a specific model

```elixir
openai |> Model.retrieve("text-davinci-003")
```

### [Completion](https://platform.openai.com/docs/api-reference/completions)

```elixir
alias OpenaiEx.Completion
```

To [create](https://platform.openai.com/docs/api-reference/completions/create) a completion, first define the structure.

```elixir
completion =
  Completion.new(
    model: "text-davinci-003",
    prompt: "Say this is a test",
    max_tokens: 100,
    temperature: 0
  )
```

then call the endpoint

```elixir
comp_response = openai |> Completion.create(completion)
```

### [Chat Completion](https://platform.openai.com/docs/api-reference/chat/completions)

```elixir
alias OpenaiEx.ChatCompletion
alias OpenaiEx.ChatMessage
```

First we define the request structure, which includes the messages needed for the chat

```elixir
chat_completion =
  ChatCompletion.new(model: "gpt-3.5-turbo", messages: [ChatMessage.user("Hello")])
```

Finally we call the [endpoint](https://platform.openai.com/docs/api-reference/chat/completions/create)

```elixir
chat_response = openai |> ChatCompletion.create(chat_completion)
```
