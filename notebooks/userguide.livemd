# OpenaiEx User Guide

```elixir
Mix.install([
  {:openai_ex, path: Path.join(__DIR__, "..")},
  {:kino, "~> 0.9.2"}
])
```

## Introduction

`OpenaiEx` is an Elixir library that provides a community-maintained client for the OpenAI API.

The library closely follows the structure of the [official OpenAI API client libraries](https://platform.openai.com/docs/api-reference) for [Python](https://github.com/openai/openai-python) and [JavaScript](https://github.com/openai/openai-node), making it easy to understand and reuse existing documentation.

To learn how to use OpenaiEx, you can refer to the relevant parts of the official OpenAI API reference documentation, which we link to throughout this document.

This file is an executable Livebook, which means you can interactively run and modify the code samples provided. We encourage you to [open it in Livebook](https://livebook.dev/run?url=https://github.com/restlessronin/openai_ex/blob/v0.1.1/notebooks/userguide.livemd) and try out the code for yourself!

## Installation

You can install OpenaiEx using Mix:

### In Livebook

Add the following code to the first connection cell:

<!-- livebook:{"force_markdown":true} -->

```elixir
Mix.install(
  [
    {:openai_ex, "~> 0.1.1"}
  ],
)
```

### In a Mix Project

Add the following to your mix.exs file:

<!-- livebook:{"force_markdown":true} -->

```elixir
def deps do
  [
    {:openai_ex, "~> 0.1.1"}
  ]
end
```

## Authentication

To authenticate with the OpenAI API, you will need an API key. We recommend storing your API key in an environment variable. Since we are using Livebook, we can store this and other evironment variables as [Livebook Hub Secrets](https://news.livebook.dev/hubs-and-secret-management---launch-week-1---day-3-3tMaJ2).

```elixir
apikey = System.fetch_env!("LB_OPENAI_API_KEY")
openai = OpenaiEx.new(apikey)
```

You can also specify an organization if you are a member of more than one:

```elixir
# organization = System.fetch_env!("LB_OPENAI_ORGANIZATION")
# openai = OpenaiEx.new(apikey, organization)
```

For more information on authentication, see the [OpenAI API Authentication reference](https://platform.openai.com/docs/api-reference/authentication).

## Model

### List Models

To list all available models, use the [`Model.list()`](https://platform.openai.com/docs/api-reference/models/list) function:

```elixir
alias OpenaiEx.Model

openai |> Model.list()
```

### Retrieve Models

To retrieve information about a specific model, use the [`Model.retrieve()`](https://platform.openai.com/docs/api-reference/models/retrieve) function:

```elixir
openai |> Model.retrieve("text-davinci-003")
```

For more information on using models, see the [OpenAI API Models reference](https://platform.openai.com/docs/api-reference/models).

## Completion

To generate a completion, you first need to define a completion request structure using the `Completion.new()` function. This function takes several parameters, such as the model ID, the prompt, the maximum number of tokens, etc.

```elixir
alias OpenaiEx.Completion

completion_req =
  Completion.new(
    model: "text-davinci-003",
    prompt: "Say this is a test",
    max_tokens: 100,
    temperature: 0
  )
```

Once you have defined the completion request structure, you can generate a completion using the [`Completion.create()`](https://platform.openai.com/docs/api-reference/completions/create) function:

```elixir
comp_response = openai |> Completion.create(completion_req)
```

For more information on generating completions, see the [OpenAI API Completions reference](https://platform.openai.com/docs/api-reference/completions).

## Chat Completion

To generate a chat completion, you need to define a chat completion request structure using the `ChatCompletion.new()` function. This function takes several parameters, such as the model ID and a list of chat messages. We have a module `ChatMessage` which helps create messages in the [chat format](https://platform.openai.com/docs/guides/chat/introduction).

```elixir
alias OpenaiEx.ChatCompletion
alias OpenaiEx.ChatMessage

chat_req = ChatCompletion.new(model: "gpt-3.5-turbo", messages: [ChatMessage.user("Hello")])
```

You can generate a chat completion using the [`ChatCompletion.create()`](https://platform.openai.com/docs/api-reference/chat/completions/create) function:

```elixir
chat_response = openai |> ChatCompletion.create(chat_req)
```

For more information on generating chat completions, see the [OpenAI API Chat Completions reference](https://platform.openai.com/docs/api-reference/chat/completions).

## Edit

First you need to define an edit request structure using the `Edit.new()` function. This function takes several parameters, such as the model ID, an input and an instruction.

```elixir
alias OpenaiEx.Edit

edit_req =
  Edit.new(
    model: "text-davinci-edit-001",
    input: "What day of the wek is it?",
    instruction: "Fix the spelling mistakes"
  )
```

To generate the edit, call the [`Edit.create()`](https://platform.openai.com/docs/api-reference/edits) function.

```elixir
edit_response = openai |> Edit.create(edit_req)
```

For more information on generating edits, see the [OpenAI API Edit reference](https://platform.openai.com/docs/api-reference/edits).

## Image

### Generate Image

We define the image creation request structure using the `Image.new` function

```elixir
alias OpenaiEx.Image

img_req = Image.new(prompt: "A cute baby sea otter", size: "256x256", n: 2)
```

Then call the [`Image.create()`](https://platform.openai.com/docs/api-reference/images/create) function to generate the images.

```elixir
img_response = openai |> Image.create(img_req)
```

For more information on generating images, see the [OpenAI API Image reference](https://platform.openai.com/docs/api-reference/images).

#### Fetch the generated images

With the information in the image response, we can fetch the images from their URLs

```elixir
fetch_img = fn url -> Tesla.client([]) |> Tesla.get!(url) end

fetched_images = img_response["data"] |> Enum.map(fn i -> i["url"] |> fetch_img.() end)
```

#### View the generated images

Finally, we can render the images using Kino

```elixir
to_kino = fn req_r ->
  Kino.Image.new(req_r.body, "image/png")
end

fetched_images
|> Enum.map(fn r -> r |> to_kino.() |> Kino.render() end)
```

### Edit Image

We define an image edit request structure using the `Image.Edit.new()` function. This function requires an image and a mask. We will

<!-- livebook:{"break_markdown":true} -->

### Image Variations

We define an image variation request structure using the `Image.Variation.new()` function. This function requires an image.

```elixir
img_to_vary = fetched_images |> List.first() |> Map.get(:body)
```

```elixir
img_var_req = Image.Variation.new(image: img_to_vary, size: "256x256")
```

Then call the [`Image.create_variation()`](https://platform.openai.com/docs/api-reference/images/create-variation) function to generate the images.

<!-- livebook:{"break_markdown":true} -->

###

```elixir
img_var_response = openai |> Image.create_variation(img_var_req)
```

```elixir
img_var_response["data"]
|> Enum.map(fn i -> i["url"] |> fetch_img.() end)
|> Enum.map(fn r -> r |> to_kino.() |> Kino.render() end)
```

For more information on images variations, see the [OpenAI API Image Variations reference](https://platform.openai.com/docs/api-reference/images/create-variation).

## Embedding

Define the embedding request structure using `Embedding.new`.

```elixir
alias OpenaiEx.Embedding

emb_req =
  Embedding.new(
    model: "text-embedding-ada-002",
    input: "The food was delicious and the waiter..."
  )
```

Then call the [`Embedding.create()`]() function.

```elixir
emb_response = openai |> Embedding.create(emb_req)
```

For more information on generating embeddings, see the [OpenAI API Embedding reference](https://platform.openai.com/docs/api-reference/embeddings/create)

<!-- livebook:{"offset":7936,"stamp":{"token":"QTEyOEdDTQ.aTDxaeImcnSSUkjn8DNYCyim-_UeROG1K3ctBWU_h68kD83HOYVtzmlnEOA.fowt7ao0ljPovgdc.YEs7JSorhE2-IkAFplfsCw8y_ZVf3HHO9BxLamPsTIpV7DTQ-bVtJ1FxjbQWY5zV4qA._OVx5aGdsD7DzfGT3Dvpzw","version":1}} -->
